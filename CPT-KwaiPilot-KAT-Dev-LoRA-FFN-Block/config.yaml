# CPT Configuration for Hyperswitch Rust Repository
# =================================================

# Repository Configuration
repository:
  name: "hyperswitch"
  path: "/workspace/CPT_Kwai/hyperswitch"
  language: "rust"


# Model Configuration
model:
  name: "Kwaipilot/KAT-Dev"
  size: "32B"
  type: "instruct"  # chat/instruct model with conversational capabilities

# Training Configuration
training:
  # LoRA settings
  lora:
    r: 64                    # Good for 32B model
    alpha: 128               # LoRA alpha (typically 2*r)
    dropout: 0.05            # LoRA dropout
    target_modules:          # Modules to apply LoRA to
      # - q_proj
      # - k_proj
      # - v_proj
      # - o_proj
      - gate_proj
      - up_proj
      - down_proj
  
  # Training hyperparameters
  num_epochs: 2              # 5 epochs for 32B model
  micro_batch_size: 8        # ðŸš€ INCREASED from 2 to 8 for H200 GPUs (141GB VRAM)
  gradient_accumulation_steps: 4  # ðŸš€ REDUCED from 8 to 4 (more actual batches, less accumulation)
  eval_batch_size: 8         # ðŸš€ INCREASED from 2 to 8 to match training batch size
  learning_rate: 0.0001     # 5e-5 for 32B
  lr_scheduler: "cosine"
  warmup_ratio: 0.03
  weight_decay: 0.1
  max_grad_norm: 0.5
  
  # Precision
  bf16: true
  fp16: false
  tf32: true
  
  # Logging & Checkpointing
  logging_steps: 10
  save_steps: 50
  eval_steps: 25
  
  # Memory optimization
  gradient_checkpointing: true
  sample_packing: false

# Weights & Biases Configuration
wandb:
  enabled: true                # Set to false to disable wandb logging
  api_key: "<WANDB API KEY>" # Paste your wandb API key here
  project: "hyperswitch-cpt"   # Project name in wandb
  entity: ""                   # Your wandb username/organization (optional)
  run_name: ""                 # Custom run name (optional, auto-generated if empty)
  tags:                        # Tags for organizing runs
    - "rust"
    - "hyperswitch"
    - "lora"
    - "code-training"
  notes: "CPT training for Hyperswitch Rust codebase"  # Description of the run
  
  # Memory optimization
  gradient_checkpointing: true
  sample_packing: false
  
# Dataset Configuration
dataset:
  output_dir: "/workspace/CPT_Kwai/dataset"
  train_split: 0.90
  val_split: 0.10
  random_seed: 42
  
  # Context window settings
  max_tokens: 8192          # Max context length for model
  overlap_tokens: 512       # Overlap for sliding window on long files
  
  # Dataset modes - for Q&A and code understanding
  modes:
    - "full_file"           # Complete files with context
    - "function_focus"      # Individual functions with context
    - "dependency_map"      # File dependencies and imports
    - "api_catalog"         # Function signatures and docs
  
  # Filtering rules
  include:
    - "*.rs"                # Include all Rust files
    - "!**/target/**"       # Exclude build artifacts
    - "!**/*.gen.rs"        # Exclude generated files
    - "!**/generated/**"    # Exclude generated directory
  
  # Test files strategy
  include_tests: true       # Tests show usage patterns - include them
  
  # Data augmentation for Q&A tasks
  augmentation:
    add_file_path: true         # Prefix with file path
    add_module_context: true    # Add import context
    extract_functions: true     # Extract individual functions
    extract_structs: true       # Extract struct definitions
    extract_traits: true        # Extract trait definitions
    add_dependencies: true      # Add import/use statements
    add_cross_references: true  # Add related file references
    
# Preprocessing Configuration
preprocessing:
  # What to keep
  keep_comments: true       # Keep documentation and important comments
  keep_docstrings: true     # Keep /// and //! comments
  keep_attributes: true     # Keep #[derive(...)] etc.
  
  # What to remove/clean
  remove_debug_prints: false  # Keep for now, they show debugging patterns
  normalize_whitespace: true  # Normalize excessive blank lines
  max_blank_lines: 2         # Max consecutive blank lines
  
  # Token counting
  tokenizer: "Kwaipilot/KAT-Dev"

# Output format
output:
  format: "jsonl"           # JSONL format for training
  fields:
    - "text"                # Main text field
    - "file_path"           # Source file path
    - "module"              # Crate/module name
    - "tokens"              # Token count
    - "type"                # Sample type (full_file, function, etc.)
    - "metadata"            # Additional metadata (functions, structs, deps)
