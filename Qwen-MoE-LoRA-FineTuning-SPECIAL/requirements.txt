# Core dependencies for MoE Fine-tuning
# Install with: pip install -r requirements.txt

# PyTorch (install from PyPI with CUDA support)
torch>=2.1.0
torchvision>=0.16.0
torchaudio>=2.1.0

# Transformers ecosystem
transformers>=4.36.0
accelerate>=0.25.0
peft>=0.7.0
bitsandbytes>=0.41.0

# Dataset and evaluation
datasets>=2.15.0
evaluate>=0.4.1
scikit-learn>=1.3.0

# Flash Attention 2 (for H200 GPUs)
flash-attn>=2.3.0

# Utilities
pyyaml>=6.0
tqdm>=4.66.0
numpy>=1.24.0
scipy>=1.11.0

# Experiment tracking
wandb>=0.16.0

# Optional: Advanced optimization
# deepspeed>=0.12.0

# Development tools
pytest>=7.4.0
black>=23.12.0
isort>=5.13.0
